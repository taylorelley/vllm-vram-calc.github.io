<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>vLLM VRAM Calculator</title>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=Space+Grotesk:wght@400;500;600;700&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg-primary: #0a0a0f;
      --bg-secondary: #12121a;
      --bg-tertiary: #1a1a24;
      --bg-card: #16161f;
      --border: #2a2a3a;
      --border-highlight: #3a3a4a;
      --text-primary: #e8e8ed;
      --text-secondary: #9090a0;
      --text-muted: #606070;
      --accent-green: #00ff88;
      --accent-green-dim: #00cc6a;
      --accent-red: #ff4466;
      --accent-yellow: #ffcc00;
      --accent-blue: #4488ff;
      --accent-purple: #aa66ff;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Space Grotesk', sans-serif;
      background: var(--bg-primary);
      color: var(--text-primary);
      min-height: 100vh;
      line-height: 1.5;
    }

    .container {
      max-width: 1400px;
      margin: 0 auto;
      padding: 2rem;
    }

    header {
      text-align: center;
      margin-bottom: 3rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid var(--border);
    }

    h1 {
      font-size: 2.5rem;
      font-weight: 700;
      letter-spacing: -0.02em;
      margin-bottom: 0.5rem;
      background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-blue) 100%);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
    }

    .subtitle {
      color: var(--text-secondary);
      font-size: 1.1rem;
    }

    .grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
    }

    @media (max-width: 1000px) {
      .grid {
        grid-template-columns: 1fr;
      }
    }

    .panel {
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 1.5rem;
    }

    .panel-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      margin-bottom: 1.5rem;
      padding-bottom: 1rem;
      border-bottom: 1px solid var(--border);
    }

    .panel-icon {
      width: 32px;
      height: 32px;
      border-radius: 8px;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1rem;
    }

    .panel-icon.gpu { background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-blue) 50%); }
    .panel-icon.model { background: linear-gradient(135deg, var(--accent-purple) 0%, var(--accent-blue) 100%); }
    .panel-icon.config { background: linear-gradient(135deg, var(--accent-yellow) 0%, var(--accent-red) 100%); }
    .panel-icon.result { background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-green-dim) 100%); }

    .panel-title {
      font-size: 1.1rem;
      font-weight: 600;
    }

    .form-group {
      margin-bottom: 1.25rem;
    }

    .form-group:last-child {
      margin-bottom: 0;
    }

    label {
      display: block;
      font-size: 0.85rem;
      font-weight: 500;
      color: var(--text-secondary);
      margin-bottom: 0.5rem;
    }

    input[type="number"], select {
      width: 100%;
      padding: 0.75rem 1rem;
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 8px;
      color: var(--text-primary);
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.95rem;
      transition: border-color 0.2s, box-shadow 0.2s;
    }

    input[type="number"]:focus, select:focus {
      outline: none;
      border-color: var(--accent-green);
      box-shadow: 0 0 0 3px rgba(0, 255, 136, 0.1);
    }

    /* Keyboard focus indicators for accessibility (WCAG 2.1 AA compliance) */
    input[type="number"]:focus-visible,
    select:focus-visible,
    button:focus-visible,
    a:focus-visible {
      outline: 2px solid var(--color-success);
      outline-offset: 2px;
    }

    input[type="number"]::-webkit-inner-spin-button {
      opacity: 1;
    }

    .input-row {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 1rem;
    }

    .hint {
      font-size: 0.75rem;
      color: var(--text-muted);
      margin-top: 0.35rem;
      font-family: 'JetBrains Mono', monospace;
    }

    /* Results Panel */
    .results-section {
      margin-bottom: 1.5rem;
      padding-bottom: 1.5rem;
      border-bottom: 1px solid var(--border);
    }

    .results-section:last-child {
      margin-bottom: 0;
      padding-bottom: 0;
      border-bottom: none;
    }

    .section-title {
      font-size: 0.8rem;
      font-weight: 600;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 1rem;
    }

    .result-row {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 0.5rem 0;
    }

    .result-label {
      color: var(--text-secondary);
      font-size: 0.9rem;
    }

    .result-value {
      font-family: 'JetBrains Mono', monospace;
      font-weight: 600;
      font-size: 0.95rem;
    }

    .result-value.highlight {
      color: var(--accent-green);
      font-size: 1.1rem;
    }

    .result-value.warning {
      color: var(--accent-yellow);
    }

    .result-value.error {
      color: var(--accent-red);
    }

    /* Memory Bar */
    .memory-bar-container {
      margin-top: 1.5rem;
    }

    .memory-bar-label {
      display: flex;
      justify-content: space-between;
      margin-bottom: 0.5rem;
      font-size: 0.85rem;
    }

    .memory-bar {
      height: 24px;
      background: var(--bg-secondary);
      border-radius: 6px;
      overflow: hidden;
      display: flex;
      position: relative;
    }

    .memory-segment {
      height: 100%;
      transition: width 0.3s ease;
      position: relative;
    }

    .memory-segment.weights { background: var(--accent-blue); }
    .memory-segment.kv-cache { background: var(--accent-purple); }
    .memory-segment.cuda-graphs { background: var(--accent-yellow); }
    .memory-segment.overhead { background: var(--accent-red); opacity: 0.7; }
    .memory-segment.free { background: var(--accent-green); opacity: 0.3; }

    .memory-legend {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      margin-top: 1rem;
    }

    .legend-item {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      font-size: 0.8rem;
      color: var(--text-secondary);
    }

    .legend-color {
      width: 12px;
      height: 12px;
      border-radius: 3px;
    }

    .legend-color.weights { background: var(--accent-blue); }
    .legend-color.kv-cache { background: var(--accent-purple); }
    .legend-color.cuda-graphs { background: var(--accent-yellow); }
    .legend-color.overhead { background: var(--accent-red); opacity: 0.7; }
    .legend-color.free { background: var(--accent-green); opacity: 0.3; }

    /* Status Badge */
    .status-badge {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      padding: 0.5rem 1rem;
      border-radius: 20px;
      font-size: 0.85rem;
      font-weight: 600;
      margin-top: 1rem;
    }

    .status-badge.ok {
      background: rgba(0, 255, 136, 0.1);
      color: var(--accent-green);
      border: 1px solid rgba(0, 255, 136, 0.3);
    }

    .status-badge.warning {
      background: rgba(255, 204, 0, 0.1);
      color: var(--accent-yellow);
      border: 1px solid rgba(255, 204, 0, 0.3);
    }

    .status-badge.error {
      background: rgba(255, 68, 102, 0.1);
      color: var(--accent-red);
      border: 1px solid rgba(255, 68, 102, 0.3);
    }

    /* Command Output */
    .command-output {
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 1rem;
      margin-top: 1.5rem;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.8rem;
      line-height: 1.6;
      overflow-x: auto;
      white-space: pre-wrap;
      word-break: break-all;
    }

    .command-output .flag {
      color: var(--accent-green);
    }

    .command-output .value {
      color: var(--accent-yellow);
    }

    /* Presets */
    .presets {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
      margin-bottom: 1.5rem;
    }

    .preset-btn {
      padding: 0.5rem 1rem;
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 6px;
      color: var(--text-secondary);
      font-family: 'Space Grotesk', sans-serif;
      font-size: 0.85rem;
      cursor: pointer;
      transition: all 0.2s;
    }

    .preset-btn:hover {
      border-color: var(--accent-green);
      color: var(--text-primary);
    }

    .preset-btn.active {
      background: rgba(0, 255, 136, 0.1);
      border-color: var(--accent-green);
      color: var(--accent-green);
    }

    /* Breakdown table */
    .breakdown-table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 1rem;
    }

    .breakdown-table th,
    .breakdown-table td {
      padding: 0.6rem 0.75rem;
      text-align: left;
      border-bottom: 1px solid var(--border);
      font-size: 0.85rem;
    }

    .breakdown-table th {
      color: var(--text-muted);
      font-weight: 500;
      font-size: 0.75rem;
      text-transform: uppercase;
      letter-spacing: 0.03em;
    }

    .breakdown-table td {
      font-family: 'JetBrains Mono', monospace;
    }

    .breakdown-table td:last-child {
      text-align: right;
    }

    .breakdown-table tr:last-child td {
      border-bottom: none;
    }

    .breakdown-table .total-row td {
      font-weight: 600;
      color: var(--accent-green);
      border-top: 2px solid var(--border);
    }

    /* HuggingFace Integration */
    .hf-input-row {
      display: flex;
      gap: 0.5rem;
    }

    .hf-input-row input[type="text"] {
      flex: 1;
      padding: 0.75rem 1rem;
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 8px;
      color: var(--text-primary);
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.9rem;
      transition: border-color 0.2s, box-shadow 0.2s;
    }

    .hf-input-row input[type="text"]:focus {
      outline: none;
      border-color: var(--accent-green);
      box-shadow: 0 0 0 3px rgba(0, 255, 136, 0.1);
    }

    .hf-input-row input[type="text"]::placeholder {
      color: var(--text-muted);
    }

    .hf-fetch-btn {
      padding: 0.75rem 1.25rem;
      background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-green-dim) 100%);
      border: none;
      border-radius: 8px;
      color: var(--bg-primary);
      font-family: 'Space Grotesk', sans-serif;
      font-size: 0.9rem;
      font-weight: 600;
      cursor: pointer;
      transition: transform 0.2s, box-shadow 0.2s;
      display: flex;
      align-items: center;
      justify-content: center;
      min-width: 80px;
    }

    .hf-fetch-btn:hover {
      transform: translateY(-1px);
      box-shadow: 0 4px 12px rgba(0, 255, 136, 0.3);
    }

    .hf-fetch-btn:active {
      transform: translateY(0);
    }

    .hf-fetch-btn:disabled {
      opacity: 0.6;
      cursor: not-allowed;
      transform: none;
    }

    .hf-fetch-btn .spinner {
      width: 18px;
      height: 18px;
      animation: spin 1s linear infinite;
    }

    @keyframes spin {
      from { transform: rotate(0deg); }
      to { transform: rotate(360deg); }
    }

    .hint.success {
      color: var(--accent-green);
    }

    .hint.error {
      color: var(--accent-red);
    }

    .hint.loading {
      color: var(--accent-yellow);
    }

    /* Model info card */
    .model-info-card {
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 1rem;
      margin-top: 0.75rem;
      margin-bottom: 1rem;
    }

    .model-info-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      margin-bottom: 0.75rem;
    }

    .model-info-icon {
      font-size: 1.5rem;
    }

    .model-info-name {
      font-weight: 600;
      font-size: 0.95rem;
      color: var(--text-primary);
    }

    .model-info-author {
      font-size: 0.8rem;
      color: var(--text-muted);
    }

    .model-info-grid {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 0.5rem 1rem;
    }

    .model-info-item {
      display: flex;
      justify-content: space-between;
      font-size: 0.8rem;
    }

    .model-info-item .label {
      color: var(--text-muted);
    }

    .model-info-item .value {
      font-family: 'JetBrains Mono', monospace;
      color: var(--text-secondary);
    }

    .model-info-tags {
      display: flex;
      flex-wrap: wrap;
      gap: 0.4rem;
      margin-top: 0.75rem;
    }

    .model-tag {
      padding: 0.2rem 0.5rem;
      background: var(--bg-tertiary);
      border-radius: 4px;
      font-size: 0.7rem;
      color: var(--text-muted);
      font-family: 'JetBrains Mono', monospace;
    }

    .model-tag.quant {
      background: rgba(170, 102, 255, 0.2);
      color: var(--accent-purple);
    }

    .model-tag.arch {
      background: rgba(68, 136, 255, 0.2);
      color: var(--accent-blue);
    }

    /* Section Divider */
    .section-divider {
      display: flex;
      align-items: center;
      margin: 1.5rem 0 1rem 0;
      gap: 1rem;
    }

    .section-divider::before,
    .section-divider::after {
      content: '';
      flex: 1;
      height: 1px;
      background: var(--border);
    }

    .section-divider span {
      font-size: 0.75rem;
      font-weight: 600;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      white-space: nowrap;
    }

    /* Quantization Estimate Card */
    .quant-estimate-card {
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 1rem;
      margin-top: 1rem;
    }

    .quant-estimate-header {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 0.75rem;
      font-size: 0.85rem;
      font-weight: 500;
      color: var(--text-secondary);
    }

    .quant-icon {
      font-size: 1rem;
    }

    .quant-estimate-values {
      display: flex;
      gap: 1.5rem;
      margin-bottom: 0.75rem;
    }

    .quant-estimate-item {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
    }

    .quant-estimate-item .label {
      font-size: 0.7rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.03em;
    }

    .quant-estimate-item .value {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.95rem;
      color: var(--text-primary);
    }

    .quant-estimate-item.total .value {
      color: var(--accent-green);
      font-weight: 600;
    }

    .apply-estimate-btn {
      width: 100%;
      padding: 0.6rem 1rem;
      background: var(--bg-tertiary);
      border: 1px solid var(--border);
      border-radius: 6px;
      color: var(--text-secondary);
      font-family: 'Space Grotesk', sans-serif;
      font-size: 0.85rem;
      cursor: pointer;
      transition: all 0.2s;
    }

    .apply-estimate-btn:hover {
      border-color: var(--accent-green);
      color: var(--accent-green);
      background: rgba(0, 255, 136, 0.05);
    }

    /* MoE specific styling */
    .moe-section {
      margin-top: 1rem;
      padding-top: 1rem;
      border-top: 1px dashed var(--border);
    }

    .moe-toggle {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      margin-bottom: 1rem;
    }

    .moe-toggle input[type="checkbox"] {
      width: 18px;
      height: 18px;
      accent-color: var(--accent-green);
      cursor: pointer;
    }

    .moe-toggle label {
      margin-bottom: 0;
      cursor: pointer;
      color: var(--text-primary);
    }

    .moe-fields {
      display: none;
    }

    .moe-fields.visible {
      display: block;
    }

    /* KV Cache Comparison Bar */
    .kv-comparison-bar-container {
      margin-top: 1rem;
      margin-bottom: 0.5rem;
    }

    .kv-comparison-bar {
      height: 20px;
      background: var(--bg-secondary);
      border-radius: 6px;
      overflow: hidden;
      position: relative;
      border: 1px solid var(--border);
    }

    .kv-comparison-fill {
      height: 100%;
      transition: width 0.3s ease, background 0.3s ease;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.7rem;
      font-weight: 600;
      color: var(--bg-primary);
      position: relative;
    }

    .kv-comparison-fill.ok {
      background: linear-gradient(90deg, var(--accent-green), var(--accent-green-dim));
    }

    .kv-comparison-fill.warning {
      background: linear-gradient(90deg, var(--accent-yellow), #e6b800);
    }

    .kv-comparison-fill.error {
      background: linear-gradient(90deg, var(--accent-red), #cc3355);
    }

    .kv-comparison-label {
      font-size: 0.75rem;
      color: var(--text-muted);
      margin-bottom: 0.3rem;
    }
  </style>
</head>
<body>
  <div class="container">
    <header role="banner">
      <h1>vLLM VRAM Calculator</h1>
      <p class="subtitle">Plan GPU memory allocation for LLM deployments</p>
    </header>

    <div class="grid">
      <!-- Left Column: Inputs -->
      <div class="inputs-column">
        <!-- GPU Configuration -->
        <div class="panel" role="region" aria-labelledby="gpu-config-title">
          <div class="panel-header">
            <div class="panel-icon gpu" aria-hidden="true">ðŸ–¥</div>
            <h2 class="panel-title" id="gpu-config-title">GPU Configuration</h2>
          </div>

          <div class="form-group">
            <label for="gpu-preset">GPU Preset</label>
            <select id="gpu-preset" aria-label="Select GPU preset from common models">
              <option value="custom">Custom (enter manually)</option>
              <optgroup label="Consumer GPUs">
                <option value="12.9">RTX 4070 Ti (12GB)</option>
                <option value="17.2">RTX 4080 (16GB)</option>
                <option value="25.8">RTX 4090 (24GB)</option>
                <option value="25.4">RTX 3090 (24GB)</option>
                <option value="34.2" selected>RTX 5090 (32GB)</option>
              </optgroup>
              <optgroup label="Professional GPUs">
                <option value="51.0">A6000 (48GB)</option>
                <option value="42.5">A100 (40GB)</option>
                <option value="85.2">A100 (80GB)</option>
                <option value="51.0">L40S (48GB)</option>
                <option value="85.5">H100 (80GB)</option>
              </optgroup>
            </select>
            <p class="hint">Actual usable VRAM from nvidia-smi (decimal GB)</p>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="gpu-vram">VRAM per GPU (GB)</label>
              <input type="number" id="gpu-vram" value="34.2" min="1" max="192" step="0.1"
                aria-label="VRAM per GPU in decimal gigabytes"
                aria-describedby="gpu-vram-hint">
              <p class="hint" id="gpu-vram-hint">1 GB = 1,000Â³ bytes (decimal)</p>
            </div>
            <div class="form-group">
              <label for="num-gpus">Number of GPUs (TP size)</label>
              <input type="number" id="num-gpus" value="2" min="1" max="8" step="1"
                aria-label="Number of GPUs for tensor parallelism">
            </div>
          </div>

          <div class="form-group">
            <label for="gpu-utilization">GPU Memory Utilization</label>
            <input type="number" id="gpu-utilization" value="0.90" min="0.5" max="0.99" step="0.01"
              aria-label="GPU memory utilization ratio"
              aria-describedby="gpu-util-hint">
            <p class="hint" id="gpu-util-hint">Typically 0.85-0.95. Lower = more headroom for spikes</p>
          </div>
        </div>

        <!-- Model Configuration -->
        <div class="panel" style="margin-top: 1.5rem;" role="region" aria-labelledby="model-config-title">
          <div class="panel-header">
            <div class="panel-icon model" aria-hidden="true">ðŸ§ </div>
            <h2 class="panel-title" id="model-config-title">Model Configuration</h2>
          </div>

          <!-- HuggingFace Integration -->
          <div class="form-group">
            <label for="hf-model-id">Load from HuggingFace</label>
            <div class="hf-input-row">
              <input type="text" id="hf-model-id" placeholder="e.g. MultiverseComputingCAI/HyperNova-60B"
                aria-label="HuggingFace model ID"
                aria-describedby="hf-status">
              <button class="hf-fetch-btn" id="hf-fetch-btn"
                aria-label="Fetch model configuration from HuggingFace">
                <span class="btn-text">Fetch</span>
                <span class="btn-loading" style="display: none;" aria-hidden="true">
                  <svg class="spinner" viewBox="0 0 24 24" aria-hidden="true">
                    <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="3" fill="none" stroke-dasharray="31.4 31.4" stroke-linecap="round"/>
                  </svg>
                </span>
              </button>
            </div>
            <p class="hint" id="hf-status" role="status" aria-live="polite">Enter a model ID and click Fetch to load config</p>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="model-weights">Model Weights (GB)</label>
              <input type="number" id="model-weights" value="36.3" min="0.1" max="500" step="0.1">
              <p class="hint">Total size on disk</p>
            </div>
            <div class="form-group">
              <label for="num-layers">Number of Layers</label>
              <input type="number" id="num-layers" value="32" min="1" max="200" step="1">
            </div>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="kv-heads">KV Heads (GQA)</label>
              <input type="number" id="kv-heads" value="8" min="1" max="128" step="1">
              <p class="hint">Key-Value attention heads</p>
            </div>
            <div class="form-group">
              <label for="head-dim">Head Dimension</label>
              <input type="number" id="head-dim" value="64" min="32" max="256" step="8">
            </div>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="attn-heads">Attention Heads (Total)</label>
              <input type="number" id="attn-heads" value="8" min="1" max="128" step="1">
              <p class="hint">Total attention heads (>= KV heads)</p>
            </div>
            <div class="form-group">
              <label for="activation-dtype">Activation Dtype</label>
              <select id="activation-dtype">
                <option value="2" selected>BF16/FP16 (2 bytes)</option>
                <option value="1">FP8 (1 byte)</option>
              </select>
            </div>
          </div>

          <!-- Quantization Configuration -->
          <div class="section-divider">
            <span>Quantization Settings</span>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="quant-method">Weight Quantization</label>
              <select id="quant-method">
                <option value="none">None (FP16/BF16)</option>
                <option value="fp8">FP8 (8-bit float)</option>
                <option value="mxfp4" selected>MXFP4 (4-bit MX)</option>
                <option value="awq">AWQ (4-bit)</option>
                <option value="gptq">GPTQ (4-bit)</option>
                <option value="bnb-nf4">BitsAndBytes NF4</option>
                <option value="bnb-int8">BitsAndBytes INT8</option>
                <option value="exl2">EXL2 (variable)</option>
                <option value="gguf">GGUF (variable)</option>
              </select>
            </div>
            <div class="form-group">
              <label for="quant-bits">Effective Bits</label>
              <input type="number" id="quant-bits" value="4" min="1" max="16" step="0.5">
              <p class="hint">Bits per weight parameter</p>
            </div>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="base-params">Base Model Params (B)</label>
              <input type="number" id="base-params" value="60" min="0.1" max="1000" step="0.1">
              <p class="hint">Unquantized parameter count</p>
            </div>
            <div class="form-group">
              <label for="quant-group-size">Group Size</label>
              <select id="quant-group-size">
                <option value="0">N/A (per-tensor)</option>
                <option value="32">32 (block-wise)</option>
                <option value="64">64</option>
                <option value="128" selected>128 (common)</option>
                <option value="256">256</option>
              </select>
            </div>
          </div>

          <div class="quant-estimate-card" id="quant-estimate-card">
            <div class="quant-estimate-header">
              <span class="quant-icon">ðŸ“¦</span>
              <span>Estimated Model Size</span>
            </div>
            <div class="quant-estimate-values">
              <div class="quant-estimate-item">
                <span class="label">Weights</span>
                <span class="value" id="est-weights">-</span>
              </div>
              <div class="quant-estimate-item">
                <span class="label">Scales/Zeros</span>
                <span class="value" id="est-scales">-</span>
              </div>
              <div class="quant-estimate-item total">
                <span class="label">Total</span>
                <span class="value" id="est-total">-</span>
              </div>
            </div>
            <button class="apply-estimate-btn" id="apply-estimate-btn">Apply Estimate â†’</button>
          </div>
        </div>

      </div>

      <!-- Right Column: Results -->
      <div class="results-column">
        <!-- vLLM Configuration -->
        <div class="panel">
          <div class="panel-header">
            <div class="panel-icon config">âš™</div>
            <h2 class="panel-title">vLLM Configuration</h2>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="max-model-len">Max Model Length</label>
              <input type="number" id="max-model-len" value="131072" min="1024" max="1048576" step="1024">
              <p class="hint">Maximum context window</p>
            </div>
            <div class="form-group">
              <label for="max-num-seqs">Max Num Seqs</label>
              <input type="number" id="max-num-seqs" value="8" min="1" max="256" step="1">
              <p class="hint">Concurrent sequences</p>
            </div>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="max-batched-tokens">Max Batched Tokens</label>
              <input type="number" id="max-batched-tokens" value="65536" min="1024" max="262144" step="1024">
              <p class="hint">Tokens per forward pass</p>
            </div>
            <div class="form-group">
              <label for="kv-cache-dtype">KV Cache Dtype</label>
              <select id="kv-cache-dtype">
                <option value="2" selected>BF16/FP16 (2 bytes)</option>
                <option value="1">FP8 (1 byte)</option>
              </select>
            </div>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="cuda-graphs">CUDA Graphs</label>
              <select id="cuda-graphs">
                <option value="1" selected>Enabled (calculated)</option>
                <option value="0">Disabled (--enforce-eager)</option>
              </select>
            </div>
            <div class="form-group">
              <label for="overhead-estimate">Overhead Estimate (GB)</label>
              <input type="number" id="overhead-estimate" value="0" min="0" step="0.01" readonly>
              <p class="hint">Calculated from activation buffers</p>
            </div>
          </div>

          <div class="input-row">
            <div class="form-group">
              <label for="overhead-padding">Extra Overhead (GB)</label>
              <input type="number" id="overhead-padding" value="1.0" min="0" max="10" step="0.1">
              <p class="hint">Framework/MoE/compilation overhead. Try 1-2 GB for large models, 0.5 GB for small</p>
            </div>
            <div class="form-group">
              <label for="overhead-notes">Overhead Inputs</label>
              <div class="hint" id="overhead-notes">
                Prefill + decode tokens Ã— hidden size per GPU Ã— dtype
              </div>
            </div>
          </div>
        </div>

        <div class="panel" style="margin-top: 1.5rem;" role="region" aria-labelledby="memory-breakdown-title">
          <div class="panel-header">
            <div class="panel-icon result" aria-hidden="true">ðŸ“Š</div>
            <h2 class="panel-title" id="memory-breakdown-title">Memory Breakdown (Per GPU)</h2>
          </div>

          <table class="breakdown-table" role="table" aria-label="Memory usage breakdown per GPU">
            <thead>
              <tr>
                <th scope="col">Component</th>
                <th scope="col">Size</th>
              </tr>
            </thead>
            <tbody id="breakdown-body">
              <!-- Filled by JS -->
            </tbody>
          </table>

          <div class="memory-bar-container">
            <div class="memory-bar-label">
              <span>Memory Usage</span>
              <span id="memory-percent" aria-live="polite">0%</span>
            </div>
            <div class="memory-bar" id="memory-bar" role="progressbar" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100" aria-label="GPU memory usage percentage">
              <!-- Filled by JS -->
            </div>
            <div class="memory-legend">
              <div class="legend-item"><div class="legend-color weights"></div>Weights</div>
              <div class="legend-item"><div class="legend-color kv-cache"></div>KV Cache</div>
              <div class="legend-item"><div class="legend-color cuda-graphs"></div>CUDA Graphs</div>
              <div class="legend-item"><div class="legend-color overhead"></div>Overhead</div>
              <div class="legend-item"><div class="legend-color free"></div>Free</div>
            </div>
          </div>

          <div id="status-container" role="status" aria-live="polite" aria-atomic="true"></div>
        </div>

        <!-- Capacity Analysis -->
        <div class="panel" style="margin-top: 1.5rem;">
          <div class="panel-header">
            <div class="panel-icon config">ðŸ“ˆ</div>
            <h2 class="panel-title">Capacity Analysis</h2>
          </div>

          <div class="results-section">
            <div class="section-title">KV Cache: Allocated vs. Required</div>
            <div class="result-row">
              <span class="result-label">Allocated KV Cache Space</span>
              <span class="result-value" id="kv-allocated-display">-</span>
            </div>
            <div class="result-row">
              <span class="result-label">Required (max-model-len Ã— max-num-seqs)</span>
              <span class="result-value" id="kv-required-display">-</span>
            </div>
            <div class="result-row">
              <span class="result-label">Utilization</span>
              <span class="result-value" id="kv-utilization-display">-</span>
            </div>
            <div class="kv-comparison-bar-container">
              <div class="kv-comparison-label">Required vs. Allocated</div>
              <div class="kv-comparison-bar">
                <div class="kv-comparison-fill" id="kv-comparison-fill"></div>
              </div>
            </div>
            <div id="kv-comparison-status"></div>
          </div>

          <div class="results-section">
            <div class="section-title">KV Cache Capacity</div>
            <div class="result-row">
              <span class="result-label">Available for KV Cache</span>
              <span class="result-value" id="kv-available">-</span>
            </div>
            <div class="result-row">
              <span class="result-label">Bytes per Token</span>
              <span class="result-value" id="bytes-per-token">-</span>
            </div>
            <div class="result-row">
              <span class="result-label">Max Tokens in Cache</span>
              <span class="result-value highlight" id="max-tokens">-</span>
            </div>
          </div>

          <div class="results-section">
            <div class="section-title">Effective Limits</div>
            <div class="result-row">
              <span class="result-label">Max Context (1 seq)</span>
              <span class="result-value" id="max-context-single">-</span>
            </div>
            <div class="result-row">
              <span class="result-label">Avg Context (all seqs)</span>
              <span class="result-value" id="avg-context-all">-</span>
            </div>
            <div class="result-row">
              <span class="result-label">Recommended max-num-seqs</span>
              <span class="result-value highlight" id="recommended-seqs">-</span>
            </div>
          </div>
        </div>

        <!-- Generated Command -->
        <div class="panel" style="margin-top: 1.5rem;">
          <div class="panel-header">
            <div class="panel-icon model">ðŸ’»</div>
            <h2 class="panel-title">Generated vLLM Command</h2>
          </div>
          <div class="command-output" id="command-output">
            <!-- Filled by JS -->
          </div>
        </div>
      </div>
    </div>
  </div>

  <script>
    // DOM Elements
    const inputs = {
      gpuVram: document.getElementById('gpu-vram'),
      numGpus: document.getElementById('num-gpus'),
      gpuUtilization: document.getElementById('gpu-utilization'),
      modelWeights: document.getElementById('model-weights'),
      numLayers: document.getElementById('num-layers'),
      kvHeads: document.getElementById('kv-heads'),
      headDim: document.getElementById('head-dim'),
      attnHeads: document.getElementById('attn-heads'),
      maxModelLen: document.getElementById('max-model-len'),
      maxNumSeqs: document.getElementById('max-num-seqs'),
      maxBatchedTokens: document.getElementById('max-batched-tokens'),
      kvCacheDtype: document.getElementById('kv-cache-dtype'),
      activationDtype: document.getElementById('activation-dtype'),
      cudaGraphs: document.getElementById('cuda-graphs'),
      overheadEstimate: document.getElementById('overhead-estimate'),
      overheadPadding: document.getElementById('overhead-padding')
    };

    // Quantization inputs (defined early for preset handlers)
    const quantInputs = {
      method: document.getElementById('quant-method'),
      bits: document.getElementById('quant-bits'),
      baseParams: document.getElementById('base-params'),
      groupSize: document.getElementById('quant-group-size')
    };

    const applyEstimateBtn = document.getElementById('apply-estimate-btn');

    // Quantization method presets
    const quantPresets = {
      'none': { bits: 16, hasScales: false },
      'fp8': { bits: 8, hasScales: false },
      'mxfp4': { bits: 4, hasScales: true, scaleOverhead: 0.125 },
      'awq': { bits: 4, hasScales: true, scaleOverhead: 0.1 },
      'gptq': { bits: 4, hasScales: true, scaleOverhead: 0.1 },
      'bnb-nf4': { bits: 4, hasScales: true, scaleOverhead: 0.125 },
      'bnb-int8': { bits: 8, hasScales: true, scaleOverhead: 0.0625 },
      'exl2': { bits: 4, hasScales: true, scaleOverhead: 0.15 },
      'gguf': { bits: 4, hasScales: true, scaleOverhead: 0.1 }
    };

    function calculateQuantEstimate() {
      const method = quantInputs.method.value;
      const bits = parseFloat(quantInputs.bits.value);
      const baseParams = parseFloat(quantInputs.baseParams.value) * 1e9;
      const groupSize = parseInt(quantInputs.groupSize.value);
      const preset = quantPresets[method];

      // Use decimal GB (1e9) for consistency with main calculation
      const weightBytes = baseParams * (bits / 8);
      const weightGB = weightBytes / 1e9;

      let scaleGB = 0;
      if (preset?.hasScales && groupSize > 0) {
        const numGroups = baseParams / groupSize;
        const scaleBytes = numGroups * 2;
        const zeroBytes = method.includes('awq') || method.includes('gptq') ? numGroups * 2 : 0;
        scaleGB = (scaleBytes + zeroBytes) / 1e9;
      } else if (preset?.scaleOverhead) {
        scaleGB = weightGB * preset.scaleOverhead;
      }

      const totalGB = weightGB + scaleGB;

      document.getElementById('est-weights').textContent = weightGB.toFixed(2) + ' GB';
      document.getElementById('est-scales').textContent = scaleGB.toFixed(2) + ' GB';
      document.getElementById('est-total').textContent = totalGB.toFixed(2) + ' GB';

      return totalGB;
    }

    // HuggingFace Integration
    const hfModelId = document.getElementById('hf-model-id');
    const hfFetchBtn = document.getElementById('hf-fetch-btn');
    const hfStatus = document.getElementById('hf-status');
    const btnText = hfFetchBtn.querySelector('.btn-text');
    const btnLoading = hfFetchBtn.querySelector('.btn-loading');

    // Model info card container (will be created dynamically)
    let modelInfoCard = null;

    // HuggingFace API cache using localStorage (7-day TTL)
    const HF_CACHE_PREFIX = 'vllm_calc_hf_';
    const HF_CACHE_TTL = 7 * 24 * 60 * 60 * 1000; // 7 days in milliseconds

    function getCachedModel(modelId) {
      try {
        const cacheKey = HF_CACHE_PREFIX + modelId;
        const cached = localStorage.getItem(cacheKey);
        if (!cached) return null;

        const { data, timestamp } = JSON.parse(cached);
        const age = Date.now() - timestamp;

        if (age > HF_CACHE_TTL) {
          localStorage.removeItem(cacheKey);
          return null;
        }

        return data;
      } catch (error) {
        console.error('Cache read error:', error);
        return null;
      }
    }

    function cacheModel(modelId, data) {
      try {
        const cacheKey = HF_CACHE_PREFIX + modelId;
        const cacheData = {
          data: data,
          timestamp: Date.now()
        };
        localStorage.setItem(cacheKey, JSON.stringify(cacheData));

        // Clean old cache entries (keep only 50 most recent)
        cleanOldCache();
      } catch (error) {
        console.error('Cache write error:', error);
      }
    }

    function cleanOldCache() {
      try {
        const cacheEntries = [];
        for (let i = 0; i < localStorage.length; i++) {
          const key = localStorage.key(i);
          if (key && key.startsWith(HF_CACHE_PREFIX)) {
            const item = JSON.parse(localStorage.getItem(key));
            cacheEntries.push({ key, timestamp: item.timestamp });
          }
        }

        // Sort by timestamp descending
        cacheEntries.sort((a, b) => b.timestamp - a.timestamp);

        // Remove old entries beyond 50
        for (let i = 50; i < cacheEntries.length; i++) {
          localStorage.removeItem(cacheEntries[i].key);
        }
      } catch (error) {
        console.error('Cache cleanup error:', error);
      }
    }

    async function fetchHuggingFaceModel(modelId) {
      // Clean up model ID
      modelId = modelId.trim();
      if (!modelId) {
        throw new Error('Please enter a model ID');
      }

      // Create abort controller for timeout (10 seconds)
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 10000);

      try {
        // Fetch model info from HF API
        const modelInfoUrl = `https://huggingface.co/api/models/${modelId}`;
        const configUrl = `https://huggingface.co/${modelId}/resolve/main/config.json`;

        // Fetch both in parallel with timeout
        const [modelInfoRes, configRes] = await Promise.all([
          fetch(modelInfoUrl, { signal: controller.signal }),
          fetch(configUrl, { signal: controller.signal })
        ]);

        clearTimeout(timeoutId);

        if (!modelInfoRes.ok) {
          if (modelInfoRes.status === 404) {
            throw new Error(`Model "${modelId}" not found. Please check the spelling and try again.`);
          } else if (modelInfoRes.status === 403) {
            throw new Error(`Model "${modelId}" is private or gated. You may need to authenticate.`);
          } else {
            throw new Error(`Failed to fetch model (HTTP ${modelInfoRes.status})`);
          }
        }

        const modelInfo = await modelInfoRes.json();

        let config = null;
        if (configRes.ok) {
          config = await configRes.json();
        }

        return { modelInfo, config };
      } catch (error) {
        clearTimeout(timeoutId);
        if (error.name === 'AbortError') {
          throw new Error('Request timed out. Please check your connection and try again.');
        }
        throw error;
      }
    }

    function estimateModelWeights(modelInfo, config) {
      // Try to get size from safetensors info
      // Convert to decimal GB (1 GB = 1,000,000,000 bytes) for consistency
      if (modelInfo.safetensors?.total) {
        return modelInfo.safetensors.total / 1e9; // bytes to GB (decimal)
      }

      // Try to estimate from parameters
      if (modelInfo.safetensors?.parameters) {
        const params = Object.values(modelInfo.safetensors.parameters).reduce((a, b) => a + b, 0);
        // Estimate based on dtype
        const hasQuantization = modelInfo.tags?.some(t =>
          t.includes('awq') || t.includes('gptq') || t.includes('bnb') ||
          t.includes('4bit') || t.includes('8bit') || t.includes('fp8') ||
          t.includes('mxfp4')
        );
        const bytesPerParam = hasQuantization ? 0.5 : 2; // 4-bit vs fp16
        return (params * bytesPerParam) / 1e9; // bytes to GB (decimal)
      }

      // Fallback: try to parse from model card or name
      const nameMatch = modelInfo.modelId?.match(/(\d+)[bB]/);
      if (nameMatch) {
        const billions = parseInt(nameMatch[1]);
        const hasQuantization = modelInfo.tags?.some(t => 
          t.includes('awq') || t.includes('gptq') || t.includes('bnb') || 
          t.includes('4bit') || t.includes('8bit')
        );
        return hasQuantization ? billions * 0.5 : billions * 2;
      }

      return null;
    }

    function extractModelConfig(modelInfo, config) {
      const result = {
        name: modelInfo.modelId?.split('/').pop() || 'Unknown',
        author: modelInfo.modelId?.split('/')[0] || 'Unknown',
        architecture: null,
        numLayers: null,
        attnHeads: null,
        kvHeads: null,
        headDim: null,
        maxContext: null,
        weightsGB: null,
        quantization: null,
        tags: modelInfo.tags || []
      };

      // Extract architecture
      if (config?.architectures?.length) {
        result.architecture = config.architectures[0];
      } else if (modelInfo.config?.architectures?.length) {
        result.architecture = modelInfo.config.architectures[0];
      } else if (modelInfo.pipeline_tag) {
        result.architecture = modelInfo.pipeline_tag;
      }

      // Detect quantization from tags
      const quantTags = ['awq', 'gptq', 'bnb', '4bit', '8bit', 'fp8', 'mxfp4', 'gguf', 'exl2'];
      for (const tag of result.tags) {
        const lowerTag = tag.toLowerCase();
        for (const qt of quantTags) {
          if (lowerTag.includes(qt)) {
            result.quantization = qt.toUpperCase();
            break;
          }
        }
        if (result.quantization) break;
      }

      // Extract from config.json
      if (config) {
        // Number of layers
        result.numLayers = config.num_hidden_layers || 
                          config.n_layer || 
                          config.num_layers ||
                          config.n_layers;

        // KV heads (for GQA)
        result.kvHeads = config.num_key_value_heads || 
                        config.num_kv_heads ||
                        config.kv_heads ||
                        config.num_attention_heads || // fallback to MHA
                        config.n_head;

        // Attention heads (total)
        result.attnHeads = config.num_attention_heads ||
                          config.n_head ||
                          config.attention_heads ||
                          config.num_heads;

        // Head dimension
        if (config.head_dim) {
          result.headDim = config.head_dim;
        } else if (config.hidden_size && (config.num_attention_heads || config.n_head)) {
          result.headDim = config.hidden_size / (config.num_attention_heads || config.n_head);
        }

        // Max context
        result.maxContext = config.max_position_embeddings ||
                           config.max_seq_len ||
                           config.max_sequence_length ||
                           config.n_positions ||
                           config.seq_length;
      }

      // Estimate weights
      result.weightsGB = estimateModelWeights(modelInfo, config);

      return result;
    }

    function renderModelInfoCard(modelConfig) {
      // Remove existing card if any
      if (modelInfoCard) {
        modelInfoCard.remove();
      }

      const card = document.createElement('div');
      card.className = 'model-info-card';
      card.innerHTML = `
        <div class="model-info-header">
          <span class="model-info-icon">ðŸ¤—</span>
          <div>
            <div class="model-info-name">${modelConfig.name}</div>
            <div class="model-info-author">by ${modelConfig.author}</div>
          </div>
        </div>
        <div class="model-info-grid">
          <div class="model-info-item">
            <span class="label">Architecture</span>
            <span class="value">${modelConfig.architecture || 'Unknown'}</span>
          </div>
          <div class="model-info-item">
            <span class="label">Layers</span>
            <span class="value">${modelConfig.numLayers || '?'}</span>
          </div>
          <div class="model-info-item">
            <span class="label">KV Heads</span>
            <span class="value">${modelConfig.kvHeads || '?'}</span>
          </div>
          <div class="model-info-item">
            <span class="label">Attn Heads</span>
            <span class="value">${modelConfig.attnHeads || '?'}</span>
          </div>
          <div class="model-info-item">
            <span class="label">Head Dim</span>
            <span class="value">${modelConfig.headDim || '?'}</span>
          </div>
          <div class="model-info-item">
            <span class="label">Max Context</span>
            <span class="value">${modelConfig.maxContext ? formatNumber(modelConfig.maxContext) : '?'}</span>
          </div>
          <div class="model-info-item">
            <span class="label">Est. Size</span>
            <span class="value">${modelConfig.weightsGB ? modelConfig.weightsGB.toFixed(1) + ' GB' : '?'}</span>
          </div>
        </div>
        <div class="model-info-tags">
          ${modelConfig.architecture ? `<span class="model-tag arch">${modelConfig.architecture}</span>` : ''}
          ${modelConfig.quantization ? `<span class="model-tag quant">${modelConfig.quantization}</span>` : ''}
          ${modelConfig.tags.slice(0, 5).map(t => `<span class="model-tag">${t}</span>`).join('')}
        </div>
      `;

      // Insert after the HF input row
      const hfFormGroup = hfModelId.closest('.form-group');
      hfFormGroup.after(card);
      modelInfoCard = card;
    }

    function applyModelConfig(modelConfig) {
      // Apply extracted values to form
      if (modelConfig.numLayers) {
        inputs.numLayers.value = modelConfig.numLayers;
      }
      if (modelConfig.kvHeads) {
        inputs.kvHeads.value = modelConfig.kvHeads;
      }
      if (modelConfig.attnHeads) {
        inputs.attnHeads.value = modelConfig.attnHeads;
      } else if (modelConfig.kvHeads) {
        inputs.attnHeads.value = modelConfig.kvHeads;
      }
      if (modelConfig.headDim) {
        inputs.headDim.value = Math.round(modelConfig.headDim);
      }
      if (modelConfig.maxContext) {
        inputs.maxModelLen.value = modelConfig.maxContext;
      }
      if (modelConfig.weightsGB) {
        inputs.modelWeights.value = modelConfig.weightsGB.toFixed(1);
      }

      // Apply quantization settings
      if (modelConfig.quantization) {
        const quantMap = {
          'AWQ': 'awq',
          'GPTQ': 'gptq',
          'MXFP4': 'mxfp4',
          'FP8': 'fp8',
          '4BIT': 'awq',
          '8BIT': 'bnb-int8',
          'BNB': 'bnb-nf4',
          'EXL2': 'exl2',
          'GGUF': 'gguf'
        };
        const mappedQuant = quantMap[modelConfig.quantization] || 'none';
        quantInputs.method.value = mappedQuant;
        
        // Set bits based on quant method
        const preset = quantPresets[mappedQuant];
        if (preset) {
          quantInputs.bits.value = preset.bits;
        }
      }

      // Try to set base params from model info
      if (modelConfig.baseParams) {
        quantInputs.baseParams.value = modelConfig.baseParams;
      } else if (modelConfig.name) {
        // Try to extract from name (e.g., "70B", "7b")
        const paramMatch = modelConfig.name.match(/(\d+(?:\.\d+)?)\s*[bB]/);
        if (paramMatch) {
          quantInputs.baseParams.value = parseFloat(paramMatch[1]);
        }
      }

      // Update quant estimate
      calculateQuantEstimate();

      // Recalculate
      calculate();
    }

    async function handleFetchClick() {
      const modelId = hfModelId.value.trim();

      // Check cache first
      const cached = getCachedModel(modelId);
      if (cached) {
        hfStatus.textContent = 'Loading from cache...';
        hfStatus.className = 'hint loading';

        setTimeout(() => {
          const modelConfig = extractModelConfig(cached.modelInfo, cached.config);
          renderModelInfoCard(modelConfig);
          applyModelConfig(modelConfig);

          const missingFields = [];
          if (!modelConfig.numLayers) missingFields.push('layers');
          if (!modelConfig.attnHeads) missingFields.push('attention heads');
          if (!modelConfig.kvHeads) missingFields.push('KV heads');
          if (!modelConfig.headDim) missingFields.push('head dim');
          if (!modelConfig.weightsGB) missingFields.push('size');

          if (missingFields.length > 0) {
            hfStatus.textContent = `Loaded from cache! Some values need manual entry: ${missingFields.join(', ')}`;
            hfStatus.className = 'hint warning';
          } else {
            hfStatus.textContent = `Successfully loaded ${modelConfig.name} (cached)`;
            hfStatus.className = 'hint success';
          }
        }, 100);

        return;
      }

      // Update UI state for network fetch
      hfFetchBtn.disabled = true;
      btnText.style.display = 'none';
      btnLoading.style.display = 'block';
      hfStatus.textContent = 'Fetching model config from HuggingFace...';
      hfStatus.className = 'hint loading';

      try {
        const { modelInfo, config } = await fetchHuggingFaceModel(modelId);

        // Cache the result
        cacheModel(modelId, { modelInfo, config });

        const modelConfig = extractModelConfig(modelInfo, config);

        // Render info card
        renderModelInfoCard(modelConfig);

        // Apply to form
        applyModelConfig(modelConfig);

        // Success message
        const missingFields = [];
        if (!modelConfig.numLayers) missingFields.push('layers');
        if (!modelConfig.attnHeads) missingFields.push('attention heads');
        if (!modelConfig.kvHeads) missingFields.push('KV heads');
        if (!modelConfig.headDim) missingFields.push('head dim');
        if (!modelConfig.weightsGB) missingFields.push('size');

        if (missingFields.length > 0) {
          hfStatus.textContent = `Loaded! Some values need manual entry: ${missingFields.join(', ')}`;
          hfStatus.className = 'hint warning';
        } else {
          hfStatus.textContent = `Successfully loaded ${modelConfig.name}`;
          hfStatus.className = 'hint success';
        }

      } catch (error) {
        hfStatus.textContent = `Error: ${error.message}`;
        hfStatus.className = 'hint error';

        // Remove model card on error
        if (modelInfoCard) {
          modelInfoCard.remove();
          modelInfoCard = null;
        }
      } finally {
        hfFetchBtn.disabled = false;
        btnText.style.display = 'block';
        btnLoading.style.display = 'none';
      }
    }

    hfFetchBtn.addEventListener('click', handleFetchClick);
    
    // Allow Enter key or Ctrl+Enter to trigger fetch
    hfModelId.addEventListener('keydown', (e) => {
      if (e.key === 'Enter' && (e.ctrlKey || e.metaKey || !e.shiftKey)) {
        e.preventDefault();
        handleFetchClick();
      }
    });

    // Global keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      // Ctrl/Cmd + K: Focus model search
      if ((e.ctrlKey || e.metaKey) && e.key === 'k') {
        e.preventDefault();
        hfModelId.focus();
      }

      // Escape: Clear focused input
      if (e.key === 'Escape') {
        if (document.activeElement &&
            (document.activeElement.tagName === 'INPUT' ||
             document.activeElement.tagName === 'SELECT')) {
          document.activeElement.blur();
        }
      }
    });

    // Update bits when method changes
    quantInputs.method.addEventListener('change', () => {
      const preset = quantPresets[quantInputs.method.value];
      if (preset) {
        quantInputs.bits.value = preset.bits;
      }
      calculateQuantEstimate();
    });

    // Recalculate estimate when any quant input changes
    Object.values(quantInputs).forEach(input => {
      input.addEventListener('input', calculateQuantEstimate);
      input.addEventListener('change', calculateQuantEstimate);
    });

    // Apply estimate to model weights
    applyEstimateBtn.addEventListener('click', () => {
      const estimate = calculateQuantEstimate();
      inputs.modelWeights.value = estimate.toFixed(1);
      calculate();
    });

    // Initial quant estimate
    calculateQuantEstimate();

    // GPU Preset dropdown
    const gpuPreset = document.getElementById('gpu-preset');
    gpuPreset.addEventListener('change', () => {
      const value = gpuPreset.value;
      if (value !== 'custom') {
        inputs.gpuVram.value = value;
        calculate();
      }
    });

    // Reset dropdown to "Custom" when VRAM is manually edited
    inputs.gpuVram.addEventListener('input', () => {
      const currentValue = parseFloat(inputs.gpuVram.value);
      const presetValue = parseFloat(gpuPreset.value);

      // If the value doesn't match the current preset, switch to "custom"
      if (gpuPreset.value !== 'custom' && currentValue !== presetValue) {
        gpuPreset.value = 'custom';
      }
    });

    // Add input listeners
    Object.values(inputs).forEach(input => {
      input.addEventListener('input', calculate);
      input.addEventListener('change', calculate);
    });

    function formatBytes(gb) {
      if (gb >= 1) return gb.toFixed(2) + ' GB';
      return (gb * 1024).toFixed(0) + ' MB';
    }

    function formatNumber(num) {
      if (num >= 1000000) return (num / 1000000).toFixed(1) + 'M';
      if (num >= 1000) return (num / 1000).toFixed(1) + 'K';
      return num.toFixed(0);
    }

    function toNumber(value, fallback = 0) {
      const parsed = Number.parseFloat(value);
      return Number.isFinite(parsed) ? parsed : fallback;
    }

    function toInt(value, fallback = 0) {
      const parsed = Number.parseInt(value, 10);
      return Number.isFinite(parsed) ? parsed : fallback;
    }

    function calculate() {
      // UNITS: All memory values use decimal GB (1 GB = 1,000,000,000 bytes)
      // This matches GPU manufacturer specs and is consistent throughout calculations.
      // Note: vLLM reports in GiB (binary), where 1 GiB = 1,073,741,824 bytes.
      // Conversion: GB (decimal) Ã— 0.931323 â‰ˆ GiB (binary)

      // Get values
      const gpuVram = Math.max(0, toNumber(inputs.gpuVram.value));  // GB (decimal)
      const numGpus = Math.max(1, toInt(inputs.numGpus.value, 1));
      const gpuUtilization = Math.min(1, Math.max(0, toNumber(inputs.gpuUtilization.value)));
      const modelWeights = Math.max(0, toNumber(inputs.modelWeights.value));  // GB (decimal)
      const numLayers = Math.max(1, toInt(inputs.numLayers.value, 1));
      const kvHeads = Math.max(1, toInt(inputs.kvHeads.value, 1));
      const headDim = Math.max(1, toInt(inputs.headDim.value, 1));
      const attnHeadsInput = Math.max(1, toInt(inputs.attnHeads.value, kvHeads));
      const maxModelLen = Math.max(1, toInt(inputs.maxModelLen.value, 1));
      const maxNumSeqs = Math.max(1, toInt(inputs.maxNumSeqs.value, 1));
      const maxBatchedTokens = Math.max(1, toInt(inputs.maxBatchedTokens.value, 1));
      const kvCacheDtypeBytes = Math.max(1, toInt(inputs.kvCacheDtype.value, 2));
      const activationDtypeBytes = Math.max(1, toInt(inputs.activationDtype.value, 2));
      const cudaGraphsEnabled = inputs.cudaGraphs.value === '1';
      const overheadPadding = Math.max(0, toNumber(inputs.overheadPadding.value));  // GB (decimal)

      // Calculate per-GPU values (all in GB decimal)
      const availableVram = gpuVram * gpuUtilization;
      const weightsPerGpu = modelWeights / numGpus;
      const attnHeads = Math.max(attnHeadsInput, kvHeads);
      if (attnHeadsInput !== attnHeads) {
        inputs.attnHeads.value = attnHeads;
      }
      const attnHeadsPerGpu = Math.ceil(attnHeads / numGpus);
      const hiddenSizePerGpu = attnHeadsPerGpu * headDim;
      const prefillTokens = maxBatchedTokens;
      const decodeTokens = maxNumSeqs;
      const activationTokens = prefillTokens + decodeTokens;
      const activationBytes = activationTokens * hiddenSizePerGpu * activationDtypeBytes;
      const overheadEstimate = (activationBytes * 2) / 1e9;
      inputs.overheadEstimate.value = overheadEstimate.toFixed(2);
      const totalOverhead = overheadEstimate + overheadPadding;
      // CUDA graphs: vLLM captures graphs for multiple batch sizes and sequence lengths.
      // PIECEWISE mode typically captures 50-100+ graphs. Multiply by 10-12x to account for this.
      // For large models (>30B) or MoE, this can be 2-4 GB. Users should adjust if needed.
      const cudaGraphMultiplier = 10;  // Empirically ~10x activation buffer for multi-graph capture
      const cudaGraphsSize = cudaGraphsEnabled ? (activationBytes / 1e9) * cudaGraphMultiplier : 0;
      const overheadNotes = document.getElementById('overhead-notes');
      overheadNotes.textContent = `${formatNumber(activationTokens)} tokens Ã— ${formatNumber(hiddenSizePerGpu)} hidden Ã— ${activationDtypeBytes} bytes Ã— 2 buffers`;
      
      // KV cache calculation
      // Per token per layer: 2 (K+V) * kvHeads * headDim * dtype_bytes
      // With TP, KV heads are split across GPUs
      const kvHeadsPerGpu = Math.ceil(kvHeads / numGpus);
      const bytesPerTokenPerLayer = 2 * kvHeadsPerGpu * headDim * kvCacheDtypeBytes;
      const bytesPerToken = bytesPerTokenPerLayer * numLayers;
      const bytesPerTokenKB = bytesPerToken / 1024;
      
      // Available for KV cache
      const fixedOverhead = weightsPerGpu + cudaGraphsSize + totalOverhead;
      const kvAvailable = Math.max(0, availableVram - fixedOverhead);
      const kvAvailableBytes = kvAvailable * 1e9; // GB to bytes (decimal)

      // Max tokens that can fit in KV cache
      const maxTokensInCache = Math.floor(kvAvailableBytes / bytesPerToken);

      // Effective limits
      const maxContextSingle = Math.min(maxModelLen, maxTokensInCache);
      const avgContextAll = Math.floor(maxTokensInCache / maxNumSeqs);

      // Recommended seqs (targeting ~32K avg context)
      const targetAvgContext = 32768;
      const recommendedSeqs = Math.max(1, Math.floor(maxTokensInCache / targetAvgContext));

      // vLLM allocates the FULL KV cache pool at startup, not just estimated active usage.
      // This matches what nvidia-smi shows in real deployments.
      const kvCacheAllocated = kvAvailable;  // Full KV cache pool allocation

      // Total usage (what nvidia-smi will show)
      const totalUsage = weightsPerGpu + kvCacheAllocated + cudaGraphsSize + totalOverhead;
      const usagePercent = gpuVram > 0 ? (totalUsage / gpuVram) * 100 : 0;
      const freeSpace = Math.max(0, gpuVram - totalUsage);

      // Update breakdown table
      const breakdownBody = document.getElementById('breakdown-body');
      breakdownBody.innerHTML = `
        <tr>
          <td>Model Weights</td>
          <td>${formatBytes(weightsPerGpu)}</td>
        </tr>
        <tr>
          <td>KV Cache Pool (allocated)</td>
          <td>${formatBytes(kvCacheAllocated)}</td>
        </tr>
        <tr>
          <td>CUDA Graphs</td>
          <td>${formatBytes(cudaGraphsSize)}</td>
        </tr>
        <tr>
          <td>Overhead (activation)</td>
          <td>${formatBytes(overheadEstimate)}</td>
        </tr>
        <tr>
          <td>Overhead (extra)</td>
          <td>${formatBytes(overheadPadding)}</td>
        </tr>
        <tr class="total-row">
          <td>Total Allocated</td>
          <td>${formatBytes(totalUsage)}</td>
        </tr>
        <tr>
          <td>Available (${(gpuUtilization * 100).toFixed(0)}% of ${gpuVram}GB)</td>
          <td>${formatBytes(availableVram)}</td>
        </tr>
        <tr>
          <td>Free Headroom</td>
          <td>${formatBytes(Math.max(0, availableVram - totalUsage))}</td>
        </tr>
      `;

      // Update memory bar
      const memoryBar = document.getElementById('memory-bar');
      const weightsPercent = gpuVram > 0 ? (weightsPerGpu / gpuVram) * 100 : 0;
      const kvPercent = gpuVram > 0 ? (kvCacheAllocated / gpuVram) * 100 : 0;
      const cudaPercent = gpuVram > 0 ? (cudaGraphsSize / gpuVram) * 100 : 0;
      const overheadPercent = gpuVram > 0 ? (totalOverhead / gpuVram) * 100 : 0;
      const freePercent = gpuVram > 0 ? (freeSpace / gpuVram) * 100 : 0;

      memoryBar.innerHTML = `
        <div class="memory-segment weights" style="width: ${weightsPercent}%"></div>
        <div class="memory-segment kv-cache" style="width: ${kvPercent}%"></div>
        <div class="memory-segment cuda-graphs" style="width: ${cudaPercent}%"></div>
        <div class="memory-segment overhead" style="width: ${overheadPercent}%"></div>
        <div class="memory-segment free" style="width: ${freePercent}%"></div>
      `;

      document.getElementById('memory-percent').textContent = usagePercent.toFixed(1) + '%';

      // Calculate KV cache comparison
      const requiredTokens = maxModelLen * maxNumSeqs;
      const requiredKvBytes = requiredTokens * bytesPerToken;
      const requiredKvGB = requiredKvBytes / 1e9;
      const kvUtilization = maxTokensInCache > 0 ? (requiredTokens / maxTokensInCache) * 100 : 0;

      // Update KV cache comparison section
      document.getElementById('kv-allocated-display').textContent = formatBytes(kvAvailable);
      document.getElementById('kv-required-display').textContent = formatBytes(requiredKvGB);

      const kvUtilizationElem = document.getElementById('kv-utilization-display');
      kvUtilizationElem.textContent = kvUtilization.toFixed(1) + '%';

      // Color code the utilization
      if (kvUtilization > 100) {
        kvUtilizationElem.className = 'result-value error';
      } else if (kvUtilization > 90) {
        kvUtilizationElem.className = 'result-value warning';
      } else {
        kvUtilizationElem.className = 'result-value highlight';
      }

      // Update KV comparison visual bar
      const kvComparisonFill = document.getElementById('kv-comparison-fill');
      const kvBarWidth = Math.min(100, kvUtilization);
      let kvBarClass;

      if (kvUtilization > 100) {
        kvBarClass = 'error';
      } else if (kvUtilization > 90) {
        kvBarClass = 'warning';
      } else if (kvUtilization > 70) {
        kvBarClass = 'warning';
      } else {
        kvBarClass = 'ok';
      }

      kvComparisonFill.style.width = kvBarWidth + '%';
      kvComparisonFill.className = `kv-comparison-fill ${kvBarClass}`;
      kvComparisonFill.textContent = kvUtilization.toFixed(1) + '%';

      // Update KV comparison status badge
      const kvComparisonStatus = document.getElementById('kv-comparison-status');
      let kvStatusClass, kvStatusText;

      if (requiredTokens > maxTokensInCache) {
        kvStatusClass = 'error';
        const shortage = requiredTokens - maxTokensInCache;
        kvStatusText = `âš  Insufficient KV Cache: Need ${formatNumber(shortage)} more tokens. Reduce max-model-len or max-num-seqs`;
      } else if (kvUtilization > 90) {
        kvStatusClass = 'warning';
        kvStatusText = `âš¡ KV Cache is ${kvUtilization.toFixed(0)}% utilized - very tight, may cause issues under load`;
      } else if (kvUtilization > 70) {
        kvStatusClass = 'warning';
        kvStatusText = `âœ“ KV Cache is ${kvUtilization.toFixed(0)}% utilized - acceptable but monitor usage`;
      } else {
        kvStatusClass = 'ok';
        const headroom = maxTokensInCache - requiredTokens;
        kvStatusText = `âœ“ Good headroom: ${formatNumber(headroom)} tokens available beyond requirements`;
      }

      kvComparisonStatus.innerHTML = `<div class="status-badge ${kvStatusClass}" style="margin-top: 1rem; width: 100%;">${kvStatusText}</div>`;

      // Update capacity analysis
      document.getElementById('kv-available').textContent = formatBytes(kvAvailable);
      document.getElementById('bytes-per-token').textContent = bytesPerTokenKB.toFixed(1) + ' KB';
      document.getElementById('max-tokens').textContent = formatNumber(maxTokensInCache);
      document.getElementById('max-context-single').textContent = formatNumber(maxContextSingle);
      document.getElementById('avg-context-all').textContent = formatNumber(avgContextAll);
      document.getElementById('recommended-seqs').textContent = recommendedSeqs;

      // Update status
      const statusContainer = document.getElementById('status-container');
      let statusClass, statusText;

      if (totalUsage > availableVram) {
        statusClass = 'error';
        statusText = 'âš  OOM Risk: Reduce context, seqs, or enable FP8 KV cache';
      } else if (totalUsage > availableVram * 0.95) {
        statusClass = 'warning';
        statusText = 'âš¡ Tight: May OOM under load. Consider reducing max-num-seqs';
      } else {
        statusClass = 'ok';
        statusText = 'âœ“ Configuration looks good';
      }

      // Calculate GiB values for vLLM comparison (1 GB decimal = 0.931323 GiB binary)
      const availableVramGiB = availableVram * 0.931323;
      const kvAvailableGiB = kvAvailable * 0.931323;

      statusContainer.innerHTML = `
        <div class="status-badge ${statusClass}">${statusText}</div>
        <p class="hint" style="margin-top: 1rem; text-align: center;">
          ðŸ’¡ vLLM comparison: Available ${availableVramGiB.toFixed(2)} GiB (binary) â€¢ KV cache ${kvAvailableGiB.toFixed(2)} GiB
        </p>
      `;

      // Generate command
      const commandOutput = document.getElementById('command-output');
      let command = `<span class="flag">--model</span> <span class="value">MODEL_NAME</span>\n`;
      command += `<span class="flag">--tensor-parallel-size</span> <span class="value">${numGpus}</span>\n`;
      command += `<span class="flag">--max-model-len</span> <span class="value">${maxModelLen}</span>\n`;
      command += `<span class="flag">--max-num-seqs</span> <span class="value">${maxNumSeqs}</span>\n`;
      command += `<span class="flag">--max-num-batched-tokens</span> <span class="value">${maxBatchedTokens}</span>\n`;
      command += `<span class="flag">--gpu-memory-utilization</span> <span class="value">${gpuUtilization}</span>\n`;
      command += `<span class="flag">--enable-chunked-prefill</span>\n`;
      
      if (!cudaGraphsEnabled) {
        command += `<span class="flag">--enforce-eager</span>\n`;
      }
      
      if (numGpus > 1) {
        command += `<span class="flag">--disable-custom-all-reduce</span>\n`;
      }

      commandOutput.innerHTML = command;
    }

    // ============================================================================
    // CONFIGURATION AUTO-SAVE & RESTORE
    // ============================================================================

    const CONFIG_STORAGE_KEY = 'vllm_calc_config_v1';

    function saveConfiguration() {
      try {
        const config = {
          gpuVram: inputs.gpuVram.value,
          numGpus: inputs.numGpus.value,
          gpuUtilization: inputs.gpuUtilization.value,
          modelWeights: inputs.modelWeights.value,
          numLayers: inputs.numLayers.value,
          kvHeads: inputs.kvHeads.value,
          headDim: inputs.headDim.value,
          attnHeads: inputs.attnHeads.value,
          maxModelLen: inputs.maxModelLen.value,
          maxNumSeqs: inputs.maxNumSeqs.value,
          maxBatchedTokens: inputs.maxBatchedTokens.value,
          kvCacheDtype: inputs.kvCacheDtype.value,
          activationDtype: inputs.activationDtype.value,
          cudaGraphs: inputs.cudaGraphs.value,
          overheadPadding: inputs.overheadPadding.value,
          quantMethod: quantInputs.method.value,
          quantBits: quantInputs.bits.value,
          baseParams: quantInputs.baseParams.value,
          groupSize: quantInputs.groupSize.value,
          timestamp: Date.now()
        };

        localStorage.setItem(CONFIG_STORAGE_KEY, JSON.stringify(config));
      } catch (error) {
        console.error('Failed to save configuration:', error);
      }
    }

    function restoreConfiguration() {
      try {
        const saved = localStorage.getItem(CONFIG_STORAGE_KEY);
        if (!saved) return false;

        const config = JSON.parse(saved);

        // Check if saved config is recent (within 30 days)
        const age = Date.now() - (config.timestamp || 0);
        if (age > 30 * 24 * 60 * 60 * 1000) {
          localStorage.removeItem(CONFIG_STORAGE_KEY);
          return false;
        }

        // Restore values
        if (config.gpuVram) inputs.gpuVram.value = config.gpuVram;
        if (config.numGpus) inputs.numGpus.value = config.numGpus;
        if (config.gpuUtilization) inputs.gpuUtilization.value = config.gpuUtilization;
        if (config.modelWeights) inputs.modelWeights.value = config.modelWeights;
        if (config.numLayers) inputs.numLayers.value = config.numLayers;
        if (config.kvHeads) inputs.kvHeads.value = config.kvHeads;
        if (config.headDim) inputs.headDim.value = config.headDim;
        if (config.attnHeads) inputs.attnHeads.value = config.attnHeads;
        if (config.maxModelLen) inputs.maxModelLen.value = config.maxModelLen;
        if (config.maxNumSeqs) inputs.maxNumSeqs.value = config.maxNumSeqs;
        if (config.maxBatchedTokens) inputs.maxBatchedTokens.value = config.maxBatchedTokens;
        if (config.kvCacheDtype) inputs.kvCacheDtype.value = config.kvCacheDtype;
        if (config.activationDtype) inputs.activationDtype.value = config.activationDtype;
        if (config.cudaGraphs) inputs.cudaGraphs.value = config.cudaGraphs;
        if (config.overheadPadding) inputs.overheadPadding.value = config.overheadPadding;
        if (config.quantMethod) quantInputs.method.value = config.quantMethod;
        if (config.quantBits) quantInputs.bits.value = config.quantBits;
        if (config.baseParams) quantInputs.baseParams.value = config.baseParams;
        if (config.groupSize) quantInputs.groupSize.value = config.groupSize;

        return true;
      } catch (error) {
        console.error('Failed to restore configuration:', error);
        return false;
      }
    }

    // Debounced save (2 seconds after last change)
    const debouncedConfigSave = debounce(saveConfiguration, 2000);

    // Auto-save on any input change
    Object.values(inputs).forEach(input => {
      input.addEventListener('input', debouncedConfigSave);
      input.addEventListener('change', debouncedConfigSave);
    });

    Object.values(quantInputs).forEach(input => {
      input.addEventListener('input', debouncedConfigSave);
      input.addEventListener('change', debouncedConfigSave);
    });

    // ============================================================================
    // INITIAL SETUP
    // ============================================================================

    // Restore configuration on page load
    const restored = restoreConfiguration();

    // Initial calculation (after restoring config)
    calculate();
  </script>
</body>
</html>
